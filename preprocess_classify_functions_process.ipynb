{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117adde1-cef2-4417-965c-b96d3813b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Start importing the functions for preprocessing\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0aabd36-b987-4227-b6b3-e6427b68bc64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#try importing to add extra data\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_process_csv(filename):\n",
    "    #\n",
    "    df = pd.read_csv(filename,header=None)\n",
    "    \n",
    "    #create the correct headers\n",
    "    df.columns = [\"Action\", \"ParentProcessGuid\", \"Hostname\", \"unknown\", \"Object\", \"ProcessGuid\", \"Pid\", \"Ppid\", \"Principal\", \"Acuity_level\", \"CommandLine\", \"Image_path\", \"Parent_image_path\", \"Sid\", \"User\", \"Tid\", \"Timestamp\"]\n",
    "    \n",
    "    #create the correct headers\n",
    "    df['CommandLine_length']  = df['CommandLine'].str.len()\n",
    "    \n",
    "    #Only take the create action instead of open and terminate \n",
    "    df = df.drop(df[df['Action'] == 'OPEN'].index)\n",
    "    df = df.drop(df[df['Action'] == 'TERMINATE'].index)\n",
    "    \n",
    "    #Convert datetime to time data\n",
    "    df['timestamp_str'] = pd.to_datetime(df['Timestamp'])\n",
    "    \n",
    "    #Drop the old timestamp colum\n",
    "    df.drop(columns=['Timestamp'], inplace=True)\n",
    "    \n",
    "    #Erstatt tomme felt med None\n",
    "    df.fillna('None', inplace=True)\n",
    "    \n",
    "    #change ending of filename\n",
    "    \n",
    "\n",
    "    #rename ending of file\n",
    "    fancyending = filename.replace(\"_process.csv\", \"_process_nodes.csv\")\n",
    "    \n",
    "    #create the csv file with all attributes\n",
    "    df.to_csv(fancyending,index=False)\n",
    "    \n",
    "    #rename ending of file\n",
    "    fancyending = filename.replace(\"_process.csv\", \"_process_relations.csv\")\n",
    "    \n",
    "    relations=df[['ParentProcessGuid', 'ProcessGuid']].copy() \n",
    "\n",
    "    relations.to_csv(fancyending,index=False)\n",
    "    \n",
    "    return fancyending\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4512e78f-2513-484b-b4a6-15627c295923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try importing to add extra data\n",
    "##modified \n",
    "##Drop inbound data\n",
    "##Drop where destination is 127.0.0.1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_flow_csv(filename):\n",
    "    #\n",
    "    df = pd.read_csv(filename,header=None)\n",
    "    \n",
    "    #create the correct headers\n",
    "    df.columns = [\"Action\", \"ProcessGuid\", \"Hostname\", \"unknown\", \"Object\", \"unkownProcessGuidish\", \"Pid\", \"Ppid\", \"Principal\", \"Acuity_level\", \"DestinationIp\", \"DestinationPort\", \"Initiated\", \"Image_path\",\"Protocol\", \"size\", \"SourceIp\", \"SourcePort\",\"Tid\", \"Timestamp\"]\n",
    "    \n",
    "    \n",
    "    #Only take the Message session\n",
    "    df = df.drop(df[df['Action'] == 'MESSAGE'].index)\n",
    "    df = df.drop(df[df['Action'] == 'TERMINATE'].index)\n",
    "    df = df.drop(df[df['Action'] == 'OPEN'].index)\n",
    "    #Only take outbound\n",
    "    df = df.drop(df[df['Initiated'] == 'inbound'].index)\n",
    "    #drop where destination is 127.0.0.1\n",
    "    df = df.drop(df[df['DestinationIp'] == '127.0.0.1'].index)\n",
    "    #df = df.drop(df[df['Action'] == 'OPEN'].index)\n",
    "    #df = df.drop(df[df['Action'] == 'TERMINATE'].index)\n",
    "    #df = df.drop(df[df['Action'] == 'START'].index)\n",
    "    \n",
    "    #Convert datetime to time data\n",
    "    df['timestamp_str'] = pd.to_datetime(df['Timestamp'])\n",
    "    \n",
    "    #Drop the old timestamp colum\n",
    "    df.drop(columns=['Timestamp'], inplace=True)\n",
    "    \n",
    "    #Erstatt tomme felt med None\n",
    "    df.fillna('None', inplace=True)\n",
    "    \n",
    "    #change ending of filename\n",
    "    #create the csv file with all attributes\n",
    "\n",
    "    #rename ending of file\n",
    "    fancyending = filename.replace(\"_flow.csv\", \"_network_node.csv\")\n",
    "    \n",
    "    #create the csv file with all attributes\n",
    "    df.to_csv(fancyending,index=False)\n",
    "    \n",
    "    #Extract only the unique processguids from the nodefile\n",
    "    df_relations=df['ProcessGuid'].unique()\n",
    "    \n",
    "    #convert to a panda dataframe again\n",
    "    relations = pd.DataFrame(df_relations)\n",
    "    \n",
    "    #Recreate the header name\n",
    "    relations.columns = [ \"ProcessGuid\"]\n",
    "        \n",
    "    #Prepare the filename\n",
    "    fancyending = filename.replace(\"_flow.csv\", \"_network_relations.csv\")\n",
    "     \n",
    "    #create the csv file\n",
    "    relations.to_csv(fancyending,index=False)\n",
    "    \n",
    "    \n",
    "    return fancyending\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a916f57-d199-44a5-ab47-7aca398af2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try importing to add extra data\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_file_csv(filename):\n",
    "    #\n",
    "    df = pd.read_csv(filename,header=None)\n",
    "    \n",
    "    #create the correct headers\n",
    "    df.columns = [\"Action\", \"ProcessGuid\", \"Hostname\", \"unknown\", \"Object\", \"Possible_ProcessGuid\", \"Pid\", \"Ppid\", \"Principal\", \"Acuity_level\", \"file_path\", \"Image_path\", \"info_class\", \"Sid\", \"User\", \"Tid\", \"Timestamp\"]\n",
    "    \n",
    "    \n",
    "    #Only take the create action instead of open and terminate \n",
    "    df = df.drop(df[df['Action'] == 'READ'].index)\n",
    "    df = df.drop(df[df['Action'] == 'WRITE'].index)\n",
    "    df = df.drop(df[df['Action'] == 'MODIFY'].index)\n",
    "    df = df.drop(df[df['Action'] == 'DELETE'].index)\n",
    "    df = df.drop(df[df['Action'] == 'RENAME'].index)\n",
    "    \n",
    "    #Convert datetime to time data\n",
    "    df['timestamp_str'] = pd.to_datetime(df['Timestamp'])\n",
    "    \n",
    "    #Drop the old timestamp colum\n",
    "    df.drop(columns=['Timestamp'], inplace=True)\n",
    "    \n",
    "    #Erstatt tomme felt med None\n",
    "    df.fillna('None', inplace=True)\n",
    "    \n",
    "    #change ending of filename\n",
    "    #create the csv file with all attributes\n",
    "\n",
    "    #rename ending of file\n",
    "    fancyending = filename.replace(\"_file.csv\", \"_file_nodes.csv\")\n",
    "    \n",
    "    #create the csv file with all attributes\n",
    "    df.to_csv(fancyending,index=False)\n",
    "    \n",
    "    #Extract only the unique processguids from the nodefile\n",
    "    df_relations=df['ProcessGuid'].unique()\n",
    "    \n",
    "    #convert to a panda dataframe again\n",
    "    relations = pd.DataFrame(df_relations)\n",
    "    \n",
    "    #Recreate the header name\n",
    "    relations.columns = [ \"ProcessGuid\"]\n",
    "        \n",
    "    #Prepare the filename\n",
    "    fancyending = filename.replace(\"_file.csv\", \"_file_relations.csv\")\n",
    "     \n",
    "    #create the csv file\n",
    "    relations.to_csv(fancyending,index=False)\n",
    "    \n",
    "    \n",
    "    return fancyending\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d0be7d-e66b-40d2-b1a4-6e920fc8d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_shell_csv(filename):\n",
    "    #\n",
    "    df = pd.read_csv(filename,header=None)\n",
    "    \n",
    "    #create the correct headers\n",
    "    df.columns = [\"Action\", \"ProcessGuid\", \"Hostname\", \"unknown\", \"Object\", \"Unkown_ProcessGuid\", \"Pid\", \"Ppid\", \"Principal\", \"Acuity_level\", \"CommandLine\", \"Image_path\", \"amsi_log\", \"Sid\", \"User\", \"Tid\", \"Timestamp\"]\n",
    "    \n",
    "    #Convert datetime to time data\n",
    "    df['timestamp_str'] = pd.to_datetime(df['Timestamp'])\n",
    "    \n",
    "    #Drop the old timestamp colum\n",
    "    df.drop(columns=['Timestamp'], inplace=True)\n",
    "    \n",
    "    #Drop the amsi log, no time to clean it up\n",
    "    df.drop(columns=['amsi_log'], inplace=True)\n",
    "\n",
    "    #extract the commandline into a temp panda dataframe\n",
    "    dummy=df['CommandLine'].str.split('\\n', expand=True)\n",
    "    \n",
    "    #rename the columns of the temp dataframe \n",
    "    dummy.columns = [ \"Severity_level\", \"Host_type\", \"Console_Version\", \"Host_ID\", \"CommandLine\", \"Engine_Version\", \"Runspace_ID\",\"Pipeline_ID\", \"Command_Name\",\"Command_Type\",\"Script_Name\", \"Command_Path\", \"Sequence_Number\", \"User\", \"Connected_User\", \"Shell_type\"]\n",
    "    #clean up the different rows removing what is no column header info\n",
    "    dummy['Severity_level'] = dummy['Severity_level'].str.replace('Severity = ', '')\n",
    "    dummy['Host_type'] = dummy['Host_type'].str.replace('Host Name = ', '')\n",
    "    dummy['Console_Version'] = dummy['Console_Version'].str.replace('Host Version = ', '')\n",
    "    dummy['Host_ID'] = dummy['Host_ID'].str.replace('Host ID = ', '')\n",
    "    dummy['Command_Name'] = dummy['Command_Name'].str.replace('Command Name = ', '')\n",
    "    dummy['Command_Type'] = dummy['Command_Type'].str.replace('Command Type = ', '')\n",
    "    dummy['Script_Name'] = dummy['Script_Name'].str.replace('Script Name = ', '')\n",
    "    dummy['CommandLine'] = dummy['CommandLine'].str.replace('Host Application = ', '')\n",
    "    dummy['CommandLine'] = dummy['CommandLine'].str.replace('Host Application= ', '')\n",
    "    dummy['Engine_Version'] = dummy['Engine_Version'].str.replace('Engine Version = ', '')\n",
    "    dummy['Runspace_ID'] = dummy['Runspace_ID'].str.replace('Runspace ID = ', '')\n",
    "    dummy['Command_Path'] = dummy['Command_Path'].str.replace('Command Path = ', '')\n",
    "    dummy['Sequence_Number'] = dummy['Sequence_Number'].str.replace('Sequence Number = ', '')\n",
    "    dummy['Pipeline_ID'] = dummy['Pipeline_ID'].str.replace('Pipeline ID = ', '')\n",
    "    dummy['Connected_User'] = dummy['Connected_User'].str.replace('Connected User = ', '')\n",
    "    dummy['User'] = dummy['User'].str.replace('User = ', '')\n",
    "    dummy['Shell_type'] = dummy['Shell_type'].str.replace('Shell ID = ', '')\n",
    "    \n",
    "    #drop the old commandline from the original dataframe \n",
    "    df.drop(columns=['CommandLine'], inplace=True)\n",
    "    #rename the dummy user to shell_user\n",
    "    dummy.rename(columns={'User': 'Shell_User'}, inplace=True)\n",
    "    #join them since they have the same index\n",
    "    joined_df = df.join(dummy)\n",
    "       \n",
    "    #Erstatt tomme felt med None\n",
    "    joined_df.fillna('None', inplace=True)\n",
    "    \n",
    "    #change ending of filename\n",
    "    \n",
    "    #rename ending of file\n",
    "    fancyending = filename.replace(\"_shell.csv\", \"_shell_nodes.csv\")\n",
    "    \n",
    "    #create the csv file with all attributes\n",
    "    joined_df.to_csv(fancyending,index=False)\n",
    "    \n",
    "     #Extract only the unique processguids from the nodefile\n",
    "    df_relations=joined_df['ProcessGuid'].unique()\n",
    "    \n",
    "    #convert to a panda dataframe again\n",
    "    relations = pd.DataFrame(df_relations)\n",
    "    \n",
    "    #Recreate the header name\n",
    "    relations.columns = [\"ProcessGuid\"]\n",
    "        \n",
    "    #Prepare the filename\n",
    "    fancyending = filename.replace(\"_shell.csv\", \"_shell_relations.csv\")\n",
    "     \n",
    "    #create the csv file\n",
    "    relations.to_csv(fancyending,index=False)\n",
    "\n",
    "    \n",
    "    return fancyending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d001e54-95f3-489d-ba7f-e88b1355817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start with getting the list of file names of the different types of files\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70320ac4-fcf1-40d2-8b3c-43f4149d9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the current folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "345a369e-31dc-4f92-b8e2-514002831af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/20-23\n",
      "CPU times: user 88 µs, sys: 29 µs, total: 117 µs\n",
      "Wall time: 139 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Get the current folder so that we only use the file in this folder\n",
    "import os\n",
    "\n",
    "current_folder = os.getcwd()\n",
    "print(current_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b83b216-40cc-4aa7-8e25-c72a58e3d996",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#try importing to add extra data\n",
    "##Original \n",
    "#import pandas as pd\n",
    "\n",
    "#def preprocess_flow_csv(filename):\n",
    "    #\n",
    " #   df = pd.read_csv(filename,header=None)\n",
    "    \n",
    " #   #create the correct headers\n",
    " #   df.columns = [\"Action\", \"ParentProcessGuid\", \"Hostname\", \"unknown\", \"Object\", \"ProcessGuid\", \"Pid\", \"Ppid\", \"Principal\", \"Acuity_level\", \"DestinationIp\", \"DestinationPort\", \"Initiated\", \"Image_path\",\"Protocol\", \"size\", \"SourceIp\", \"SourcePort\",\"Tid\", \"Timestamp\"]\n",
    "    \n",
    "    \n",
    "    #Only take the Start session\n",
    " #   df = df.drop(df[df['Action'] == 'MESSAGE'].index)\n",
    " #   df = df.drop(df[df['Action'] == 'TERMINATE'].index)\n",
    " #   df = df.drop(df[df['Action'] == 'OPEN'].index)\n",
    "    \n",
    "    #Convert datetime to time data\n",
    " #   df['timestamp_str'] = pd.to_datetime(df['Timestamp'])\n",
    "    \n",
    "    #Drop the old timestamp colum\n",
    " #   df.drop(columns=['Timestamp'], inplace=True)\n",
    "    \n",
    "    #Erstatt tomme felt med None\n",
    " #   df.fillna('None', inplace=True)\n",
    "    \n",
    "    #change ending of filename\n",
    "    #create the csv file with all attributes\n",
    "\n",
    "    #rename ending of file\n",
    " #   fancyending = filename.replace(\"_flow.csv\", \"_network_node.csv\")\n",
    "    \n",
    "    #create the csv file with all attributes\n",
    " #   df.to_csv(fancyending,index=False)\n",
    "    \n",
    "    \n",
    " #   return fancyending\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fad3611-e60e-45b4-89ee-9c7c0eb3f655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AIA-501-525.ecar-last_process.csv']\n",
      "CPU times: user 619 µs, sys: 203 µs, total: 822 µs\n",
      "Wall time: 2.54 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "#Gets all process files and puts them in a variable\n",
    "def get_process_files(directory):\n",
    "    process_files = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('_process.csv'):\n",
    "            process_files.append(filename)\n",
    "    return process_files\n",
    "\n",
    "process_files_result=get_process_files(current_folder)\n",
    "print(process_files_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4001baa-f2ad-40cd-b881-8771f280821e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AIA-501-525.ecar-last_flow.csv']\n",
      "CPU times: user 0 ns, sys: 865 µs, total: 865 µs\n",
      "Wall time: 524 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "#Gets all flow node files and puts them in a variable\n",
    "def get_network_flow_files(directory):\n",
    "    network_flow_files = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('_flow.csv'):\n",
    "             network_flow_files.append(filename)\n",
    "    return network_flow_files\n",
    "\n",
    "network_flow_result=get_network_flow_files(current_folder)\n",
    "print(network_flow_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6c0ad73-7d38-48f5-939d-751d4ef575d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AIA-501-525.ecar-last_file.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#Gets all file_info files and puts them in a variable\n",
    "def get_file_info_files(directory):\n",
    "    file_info_files = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('_file.csv'):\n",
    "            file_info_files.append(filename)\n",
    "    return file_info_files\n",
    "\n",
    "file_info_result=get_file_info_files(current_folder)\n",
    "print(file_info_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73185c08-141a-4b4c-ad0e-da6cba3e985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Extract the data needed for the graph database\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faf51117-c930-41a1-b52e-bb71885bc9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIA-501-525.ecar-last_process.csv\n",
      "CPU times: user 4.13 s, sys: 679 ms, total: 4.81 s\n",
      "Wall time: 4.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#prepare the process_node files from flow files\n",
    "\n",
    "for filename in process_files_result:\n",
    "    print(filename)\n",
    "    preprocess_process_csv(filename)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "656c18be-7aef-4ccb-aaf5-65e6126b87d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIA-501-525.ecar-last_flow.csv\n",
      "CPU times: user 59.6 s, sys: 11.2 s, total: 1min 10s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#prepare the network_node files from flow files\n",
    "\n",
    "for filename in network_flow_result:\n",
    "    print(filename)\n",
    "    preprocess_flow_csv(filename)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6fba56d-104a-4b23-a0e4-7d828f965b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIA-501-525.ecar-last_file.csv\n",
      "CPU times: user 16.1 s, sys: 1.56 s, total: 17.6 s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#prepare the file_info files from file_info files\n",
    "\n",
    "for filename in file_info_result:\n",
    "    print(filename)\n",
    "    preprocess_file_csv(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "366781ff-7bcd-43fb-993f-353dca20f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Compress the flow/process/file files\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51d15827-490e-4cf1-946a-55e7ef673d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.82 ms, sys: 1.96 ms, total: 3.78 ms\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#compress the files since we don't need them in a while\n",
    "import subprocess\n",
    "\n",
    "for filename in network_flow_result:\n",
    "    compressing_files=\"gzip \"+filename\n",
    "    subprocess.run(compressing_files, shell=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14cd4dbb-2065-424b-b01f-1f4bec8e8112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.83 ms, sys: 312 µs, total: 2.15 ms\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#compress the files since we don't need them in a while\n",
    "import subprocess\n",
    "\n",
    "for filename in file_info_result:\n",
    "    compressing_files=\"gzip \"+filename\n",
    "    subprocess.run(compressing_files, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9011b20-4ddc-4c45-a38b-4250140c2b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.56 ms, sys: 0 ns, total: 1.56 ms\n",
      "Wall time: 5.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#compress the files since we don't need them in a while\n",
    "import subprocess\n",
    "\n",
    "for filename in process_files_result:\n",
    "    compressing_files=\"gzip \"+filename\n",
    "    subprocess.run(compressing_files, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a64d2c55-e5ca-43c8-bbf1-3af6824fcf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Move the files to the neo4j to be imported\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14c734c2-798a-4d5b-96ab-906b28a279da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move the files to the import folders\n",
    "\n",
    "!mv *_network_node.csv ../neo4j/import/20-23/\n",
    "!mv *_network_relations.csv ../neo4j/import/20-23/\n",
    "!mv *_file_nodes.csv ../neo4j/import/20-23/\n",
    "!mv *_file_relations.csv ../neo4j/import/20-23/\n",
    "!mv *_process_relations.csv ../neo4j/import/20-23/\n",
    "!mv *_process_nodes.csv ../neo4j/import/20-23/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6f286b-ce85-4905-ac4f-73800793abd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
